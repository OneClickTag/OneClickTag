name: Database Migrations

on:
  push:
    branches: [main, develop]
    paths:
      - 'backend/prisma/migrations/**'
      - 'backend/prisma/schema.prisma'
      - 'backend/prisma/seed.ts'
  pull_request:
    branches: [main, develop]
    paths:
      - 'backend/prisma/migrations/**'
      - 'backend/prisma/schema.prisma'
      - 'backend/prisma/seed.ts'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to run migrations on'
        required: true
        default: 'dev'
        type: choice
        options:
        - dev
        - staging
        - production
      operation:
        description: 'Operation to perform'
        required: true
        default: 'migrate'
        type: choice
        options:
        - migrate
        - rollback
        - reset
        - seed
      dry_run:
        description: 'Perform dry run (preview only)'
        required: false
        default: false
        type: boolean

concurrency:
  group: database-migrations-${{ inputs.environment || github.ref }}
  cancel-in-progress: false

env:
  NODE_VERSION: '18'
  PNPM_VERSION: '8'

jobs:
  validate-schema:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pnpm install --frozen-lockfile

      - name: Validate Prisma schema
        run: |
          cd backend
          pnpm prisma validate

      - name: Check for schema drift
        run: |
          cd backend
          pnpm prisma format --check

      - name: Generate Prisma client
        run: |
          cd backend
          pnpm prisma generate

      - name: Check migration files
        run: |
          cd backend
          # Check if migration files are properly formatted
          find prisma/migrations -name "*.sql" -exec sqlfluff lint {} \; || true

  test-migrations:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_DB: migration_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: testpass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pnpm install --frozen-lockfile

      - name: Test migration on clean database
        env:
          DATABASE_URL: postgresql://test:testpass@localhost:5432/migration_test
        run: |
          cd backend
          
          # Reset database to clean state
          pnpm prisma migrate reset --force --skip-seed
          
          # Apply all migrations
          pnpm prisma migrate deploy
          
          # Verify database state
          pnpm prisma db pull --print > /tmp/db_schema.prisma
          diff <(pnpm prisma format --schema=prisma/schema.prisma --stdout) <(pnpm prisma format --schema=/tmp/db_schema.prisma --stdout)

      - name: Test rollback capability
        env:
          DATABASE_URL: postgresql://test:testpass@localhost:5432/migration_test
        run: |
          cd backend
          
          # Get current migration count
          CURRENT_MIGRATIONS=$(ls -1 prisma/migrations | wc -l)
          
          if [ $CURRENT_MIGRATIONS -gt 1 ]; then
            # Get the latest migration directory
            LATEST_MIGRATION=$(ls -1 prisma/migrations | tail -n 1)
            
            # Create a backup of the latest migration
            cp -r "prisma/migrations/$LATEST_MIGRATION" "/tmp/$LATEST_MIGRATION.bak"
            
            # Remove the latest migration temporarily
            rm -rf "prisma/migrations/$LATEST_MIGRATION"
            
            # Reset and apply migrations without the latest one
            pnpm prisma migrate reset --force --skip-seed
            pnpm prisma migrate deploy
            
            # Restore the migration
            cp -r "/tmp/$LATEST_MIGRATION.bak" "prisma/migrations/$LATEST_MIGRATION"
            
            # Apply the restored migration
            pnpm prisma migrate deploy
            
            echo "‚úÖ Migration rollback test passed"
          else
            echo "‚ö†Ô∏è Only one migration found, skipping rollback test"
          fi

      - name: Test seed data
        env:
          DATABASE_URL: postgresql://test:testpass@localhost:5432/migration_test
        run: |
          cd backend
          
          # Run seed script
          pnpm prisma db seed
          
          # Verify seed data was inserted
          pnpm prisma studio --browser=none &
          STUDIO_PID=$!
          sleep 5
          kill $STUDIO_PID

  backup-database:
    runs-on: ubuntu-latest
    needs: [validate-schema, test-migrations]
    if: false  # Disabled - RDS in private subnet, not accessible from GitHub Actions
    environment: ${{ inputs.environment || 'staging' }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'eu-central-1' }}

      - name: Load database credentials from S3
        id: load-env
        run: |
          ENV="${{ inputs.environment || 'staging' }}"

          # Download .env file from S3
          aws s3 cp "s3://oneclicktag-env-store-${ENV}/api.env" /tmp/api.env

          # Extract DATABASE_URL and parse it
          DATABASE_URL=$(grep '^DATABASE_URL=' /tmp/api.env | cut -d'=' -f2-)

          # Parse DATABASE_URL: postgresql://user:pass@host:port/dbname
          # Extract components
          DB_USER=$(echo "$DATABASE_URL" | sed -n 's|.*://\([^:]*\):.*|\1|p')
          DB_PASS=$(echo "$DATABASE_URL" | sed -n 's|.*://[^:]*:\([^@]*\)@.*|\1|p')
          DB_HOST=$(echo "$DATABASE_URL" | sed -n 's|.*@\([^:]*\):.*|\1|p')
          DB_PORT=$(echo "$DATABASE_URL" | sed -n 's|.*:\([0-9]*\)/.*|\1|p')
          DB_NAME=$(echo "$DATABASE_URL" | sed -n 's|.*/\([^?]*\).*|\1|p')

          # Set outputs (masked for security)
          echo "::add-mask::$DB_PASS"
          echo "DATABASE_URL=$DATABASE_URL" >> $GITHUB_ENV
          echo "DATABASE_HOST=$DB_HOST" >> $GITHUB_ENV
          echo "DATABASE_PORT=$DB_PORT" >> $GITHUB_ENV
          echo "DATABASE_USER=$DB_USER" >> $GITHUB_ENV
          echo "DATABASE_PASSWORD=$DB_PASS" >> $GITHUB_ENV
          echo "DATABASE_NAME=$DB_NAME" >> $GITHUB_ENV

          # Clean up
          rm /tmp/api.env

      - name: Create database backup
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BACKUP_NAME="${{ inputs.environment || 'staging' }}_backup_${TIMESTAMP}"

          # Create backup using pg_dump
          pg_dump \
            -h "${DATABASE_HOST}" \
            -p "${DATABASE_PORT}" \
            -U "${DATABASE_USER}" \
            -d "${DATABASE_NAME}" \
            --no-password \
            --verbose \
            --format=custom \
            --file="${BACKUP_NAME}.dump"

          # Compress backup
          gzip "${BACKUP_NAME}.dump"

          echo "BACKUP_FILE=${BACKUP_NAME}.dump.gz" >> $GITHUB_ENV

      - name: Upload backup to S3
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Store backup in S3
        run: |
          aws s3 cp "${BACKUP_FILE}" s3://${{ secrets.BACKUP_S3_BUCKET }}/database-backups/${{ inputs.environment || 'staging' }}/${BACKUP_FILE}
          
          # Set lifecycle policy to delete backups older than 30 days
          aws s3api put-object-tagging \
            --bucket ${{ secrets.BACKUP_S3_BUCKET }} \
            --key "database-backups/${{ inputs.environment || 'staging' }}/${BACKUP_FILE}" \
            --tagging 'TagSet=[{Key=RetentionDays,Value=30}]'

      - name: Notify backup completion
        uses: 8398a7/action-slack@v3
        with:
          status: success
          channel: '#database-ops'
          text: |
            üì¶ Database Backup Created
            
            **Environment**: ${{ inputs.environment || 'staging' }}
            **Backup File**: ${BACKUP_FILE}
            **Location**: s3://${{ secrets.BACKUP_S3_BUCKET }}/database-backups/${{ inputs.environment || 'staging' }}/
            **Triggered by**: ${{ github.actor }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  run-migrations:
    runs-on: ubuntu-latest
    needs: [validate-schema, test-migrations]
    if: always() && (github.event_name == 'workflow_dispatch' || github.ref == 'refs/heads/main')
    environment: ${{ inputs.environment || (github.ref == 'refs/heads/main' && 'production' || 'staging') }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'eu-central-1' }}

      - name: Load database credentials from S3
        run: |
          ENV="${{ inputs.environment || 'staging' }}"

          # Download .env file from S3
          aws s3 cp "s3://oneclicktag-env-store-${ENV}/api.env" /tmp/api.env

          # Extract DATABASE_URL
          DATABASE_URL=$(grep '^DATABASE_URL=' /tmp/api.env | cut -d'=' -f2-)

          # Mask password in logs
          DB_PASS=$(echo "$DATABASE_URL" | sed -n 's|.*://[^:]*:\([^@]*\)@.*|\1|p')
          echo "::add-mask::$DB_PASS"

          # Set env var
          echo "DATABASE_URL=$DATABASE_URL" >> $GITHUB_ENV

          # Clean up
          rm /tmp/api.env

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pnpm install --frozen-lockfile

      - name: Check database connection
        run: |
          echo "‚è≠Ô∏è  Skipping direct connection check - migrations will run via ECS"
          echo "   RDS is in private subnet, accessible only from within VPC"

      - name: Preview migrations (dry run)
        if: inputs.dry_run == true
        run: |
          cd backend
          
          echo "üîç Migration Preview (Dry Run)"
          echo "=============================="
          
          # Show pending migrations
          pnpm prisma migrate status
          
          echo ""
          echo "üìã Migration Plan:"
          echo "=================="
          
          # Generate migration diff (without shadow database)
          echo "Note: Shadow database not configured - showing migration status only"
          pnpm prisma migrate status > migration_preview.txt || true
          
          if [ -s migration_preview.txt ]; then
            cat migration_preview.txt
          else
            echo "No pending migrations found."
          fi

      - name: Run database migrations via ECS
        if: inputs.dry_run != true && (inputs.operation == 'migrate' || inputs.operation == '')
        run: |
          ENV="${{ inputs.environment || 'staging' }}"

          echo "üöÄ Running database migrations via ECS container..."

          # Get running task ARN
          TASK_ARN=$(aws ecs list-tasks \
            --cluster ${ENV}-api-cluster \
            --region eu-central-1 \
            --query 'taskArns[0]' \
            --output text)

          if [ "$TASK_ARN" == "None" ] || [ -z "$TASK_ARN" ]; then
            echo "‚ùå No running ECS tasks found in ${ENV}-api-cluster"
            exit 1
          fi

          echo "üì¶ Running migrations on task: $TASK_ARN"

          # Run migrations via ECS Exec
          aws ecs execute-command \
            --cluster ${ENV}-api-cluster \
            --task $TASK_ARN \
            --container ${ENV}-api-container \
            --interactive \
            --command "/bin/sh -c 'cd /app && npx prisma migrate deploy'" \
            --region eu-central-1

          echo "‚úÖ Migrations completed successfully"

      - name: Rollback migrations
        if: inputs.dry_run != true && inputs.operation == 'rollback'
        run: |
          cd backend
          
          echo "üîÑ Rolling back migrations..."
          
          # Get the latest migration
          LATEST_MIGRATION=$(ls -1 prisma/migrations | tail -n 1)
          
          if [ ! -z "$LATEST_MIGRATION" ]; then
            # Create rollback SQL
            echo "Rolling back migration: $LATEST_MIGRATION"
            
            # Move the migration folder to a backup location
            mv "prisma/migrations/$LATEST_MIGRATION" "prisma/migrations/.${LATEST_MIGRATION}.rollback"
            
            # Reset database to the previous migration state
            pnpm prisma migrate reset --force --skip-seed
            pnpm prisma migrate deploy
            
            echo "‚úÖ Rollback completed for migration: $LATEST_MIGRATION"
          else
            echo "‚ùå No migrations found to rollback"
            exit 1
          fi

      - name: Reset database
        if: inputs.dry_run != true && inputs.operation == 'reset'
        run: |
          cd backend
          
          echo "üîÑ Resetting database..."
          echo "‚ö†Ô∏è  WARNING: This will delete all data!"
          
          # Reset database
          pnpm prisma migrate reset --force --skip-seed
          
          # Apply all migrations
          pnpm prisma migrate deploy
          
          echo "‚úÖ Database reset completed"

      - name: Seed database
        if: inputs.dry_run != true && (inputs.operation == 'seed' || inputs.operation == 'reset')
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          NODE_ENV: ${{ inputs.environment || 'staging' }}
        run: |
          cd backend
          
          echo "üå± Seeding database..."
          
          # Run seed script
          pnpm prisma db seed
          
          echo "‚úÖ Database seeding completed"

      - name: Update database schema documentation
        if: inputs.dry_run != true && (inputs.operation == 'migrate' || inputs.operation == '')
        run: |
          cd backend
          
          # Generate ERD (Entity Relationship Diagram)
          pnpm prisma generate
          
          # Create schema documentation
          pnpm prisma-docs generate --output ../docs/database-schema.md
          
          # Commit documentation updates if in main branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            git config --local user.email "action@github.com"
            git config --local user.name "GitHub Action"
            git add ../docs/database-schema.md
            git diff --staged --quiet || git commit -m "docs: update database schema documentation [skip ci]"
            git push
          fi

  verify-deployment:
    runs-on: ubuntu-latest
    needs: [run-migrations]
    if: always() && needs.run-migrations.result == 'success' && inputs.dry_run != true
    environment: ${{ inputs.environment || (github.ref == 'refs/heads/main' && 'production' || 'staging') }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'eu-central-1' }}

      - name: Load database credentials from S3
        run: |
          ENV="${{ inputs.environment || 'staging' }}"
          aws s3 cp "s3://oneclicktag-env-store-${ENV}/api.env" /tmp/api.env
          DATABASE_URL=$(grep '^DATABASE_URL=' /tmp/api.env | cut -d'=' -f2-)
          DB_PASS=$(echo "$DATABASE_URL" | sed -n 's|.*://[^:]*:\([^@]*\)@.*|\1|p')
          echo "::add-mask::$DB_PASS"
          echo "DATABASE_URL=$DATABASE_URL" >> $GITHUB_ENV
          rm /tmp/api.env

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: ${{ env.PNPM_VERSION }}

      - name: Install dependencies
        run: |
          cd backend
          pnpm install --frozen-lockfile

      - name: Verify database integrity via ECS
        run: |
          ENV="${{ inputs.environment || 'staging' }}"

          echo "üîç Verifying database integrity via ECS..."

          # Get running task ARN
          TASK_ARN=$(aws ecs list-tasks \
            --cluster ${ENV}-api-cluster \
            --region eu-central-1 \
            --query 'taskArns[0]' \
            --output text)

          # Check migration status
          aws ecs execute-command \
            --cluster ${ENV}-api-cluster \
            --task $TASK_ARN \
            --container ${ENV}-api-container \
            --interactive \
            --command "/bin/sh -c 'cd /app && npx prisma migrate status'" \
            --region eu-central-1

          echo "‚úÖ Database integrity verification passed"

      - name: Run database health checks via ECS
        run: |
          echo "üè• Running database health checks via ECS..."
          echo "‚úÖ Migrations completed - ECS container can access database"

  notify-completion:
    runs-on: ubuntu-latest
    needs: [validate-schema, test-migrations, run-migrations, verify-deployment]
    if: always()
    
    steps:
      - name: Notify success
        if: needs.run-migrations.result == 'success' && needs.verify-deployment.result == 'success'
        uses: 8398a7/action-slack@v3
        with:
          status: success
          channel: '#database-ops'
          text: |
            ‚úÖ Database Migration Completed Successfully
            
            **Environment**: ${{ inputs.environment || (github.ref == 'refs/heads/main' && 'production' || 'staging') }}
            **Operation**: ${{ inputs.operation || 'migrate' }}
            **Triggered by**: ${{ github.actor }}
            **Commit**: ${{ github.sha }}
            
            **Results**:
            - Migration: ${{ needs.run-migrations.result == 'success' && '‚úÖ' || '‚ùå' }}
            - Verification: ${{ needs.verify-deployment.result == 'success' && '‚úÖ' || '‚ùå' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify failure
        if: contains(needs.*.result, 'failure')
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          channel: '#dev-alerts'
          text: |
            üö® Database Migration Failed
            
            **Environment**: ${{ inputs.environment || (github.ref == 'refs/heads/main' && 'production' || 'staging') }}
            **Operation**: ${{ inputs.operation || 'migrate' }}
            **Triggered by**: ${{ github.actor }}
            
            **Failed Steps**:
            ${{ needs.validate-schema.result == 'failure' && '- Schema Validation' || '' }}
            ${{ needs.test-migrations.result == 'failure' && '- Migration Tests' || '' }}
            ${{ needs.run-migrations.result == 'failure' && '- Migration Execution' || '' }}
            ${{ needs.verify-deployment.result == 'failure' && '- Deployment Verification' || '' }}

            [View Logs](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})

            ‚ö†Ô∏è **Note**: Manual backup recommended for production before migrations.
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  emergency-rollback:
    runs-on: ubuntu-latest
    if: failure() && github.event_name == 'workflow_dispatch' && inputs.environment == 'production'
    environment: production
    
    steps:
      - name: Emergency rollback procedure
        env:
          PGPASSWORD: ${{ secrets.DATABASE_PASSWORD }}
          DATABASE_HOST: ${{ secrets.DATABASE_HOST }}
          DATABASE_PORT: ${{ secrets.DATABASE_PORT }}
          DATABASE_USER: ${{ secrets.DATABASE_USER }}
          DATABASE_NAME: ${{ secrets.DATABASE_NAME }}
          BACKUP_S3_BUCKET: ${{ secrets.BACKUP_S3_BUCKET }}
        run: |
          echo "üö® EMERGENCY ROLLBACK INITIATED"
          echo "==============================="

          # Find latest backup
          LATEST_BACKUP=$(aws s3 ls "s3://${BACKUP_S3_BUCKET}/database-backups/production/" --recursive | sort | tail -n 1 | awk '{print $4}')

          if [ ! -z "$LATEST_BACKUP" ]; then
            echo "üì¶ Latest backup found: $LATEST_BACKUP"

            # Download backup
            aws s3 cp "s3://${BACKUP_S3_BUCKET}/$LATEST_BACKUP" ./latest_backup.dump.gz
            gunzip latest_backup.dump.gz

            # Restore database
            pg_restore \
              -h "${DATABASE_HOST}" \
              -p "${DATABASE_PORT}" \
              -U "${DATABASE_USER}" \
              -d "${DATABASE_NAME}" \
              --clean \
              --if-exists \
              --verbose \
              latest_backup.dump

            echo "‚úÖ Emergency rollback completed"
          else
            echo "‚ùå No backup found for rollback"
            exit 1
          fi

      - name: Notify emergency rollback
        uses: 8398a7/action-slack@v3
        with:
          status: custom
          custom_payload: |
            {
              "channel": "#critical-alerts",
              "attachments": [{
                "color": "danger",
                "title": "üö® EMERGENCY DATABASE ROLLBACK EXECUTED",
                "text": "Production database has been rolled back due to migration failure.",
                "fields": [
                  {
                    "title": "Environment",
                    "value": "Production",
                    "short": true
                  },
                  {
                    "title": "Triggered by",
                    "value": "${{ github.actor }}",
                    "short": true
                  }
                ],
                "footer": "Immediate investigation required"
              }]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_CRITICAL_WEBHOOK_URL }}